{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Structured Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1   Back to the Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List Assignment and Computer Memory: Two list objects foo and bar reference the same location in the computer's memory; updating foo will also modify bar, and vice versa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> foo = 'Monty'\n",
    ">>> bar = foo\n",
    ">>> foo = 'Python'\n",
    ">>> bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monty', 'Bodkin']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> foo = ['Monty', 'Python']\n",
    ">>> bar = foo\n",
    ">>> foo[1] = 'Bodkin'\n",
    ">>> bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], []]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> empty = []\n",
    ">>> nested = [empty, empty, empty]\n",
    ">>> nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Python'], ['Python']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> nested[1].append('Python')\n",
    ">>> nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], []]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> nested = [[]] * 3\n",
    ">>> nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Python'], ['Python']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> nested[1].append('Python')\n",
    ">>> nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4372866504\n",
      "4371816392\n",
      "4372868936\n"
     ]
    }
   ],
   "source": [
    ">>> print (id(nested[0]))\n",
    ">>> print (id(nested[1]))\n",
    ">>> print (id(nested[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Monty'], ['Python']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> nested = [[]] * 3\n",
    ">>> nested[1].append('Python')\n",
    ">>> nested[1] = ['Monty']\n",
    ">>> nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Monty'], ['Python']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> bar = nested\n",
    ">>> bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Monty'], ['Python']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> bar = nested[:]\n",
    ">>> bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Monty'], ['Python']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> nested[2] = ['Monty']\n",
    ">>> bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python provides two ways to check that a pair of items are the same. The ***is*** operator tests for object identity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Python'], ['Python'], ['Python'], ['Python']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> size = 5\n",
    ">>> python = ['Python']\n",
    ">>> snake_nest = [python] * size\n",
    ">>> snake_nest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> snake_nest[0] == snake_nest[1] == snake_nest[2] == snake_nest[3] == snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> snake_nest[0] is snake_nest[1] is snake_nest[2] is snake_nest[3] is snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4372355464, 4372355464, 4372355464, 4372355464, 4372355464]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> [id(snake) for snake in snake_nest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Python'], ['Python'], ['Python'], ['Python']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> import random\n",
    ">>> position = random.choice(range(size))\n",
    ">>> snake_nest[position] = ['Python']\n",
    ">>> snake_nest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> snake_nest[0] == snake_nest[1] == snake_nest[2] == snake_nest[3] == snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> snake_nest[0] is snake_nest[1] is snake_nest[2] is snake_nest[3] is snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4372925640, 4372355464, 4372355464, 4372355464, 4372355464]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> [id(snake) for snake in snake_nest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "['dog']\n"
     ]
    }
   ],
   "source": [
    ">>> mixed = ['cat', '', ['dog'], []]\n",
    ">>> for element in mixed:\n",
    "...     if element:\n",
    "...         print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    ">>> animals = ['cat', 'dog']\n",
    ">>> if 'cat' in animals:\n",
    "...     print(1)\n",
    "... elif 'dog' in animals:\n",
    "...     print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> sent = ['No', 'good', 'fish', 'goes', 'anywhere', 'without', 'a', 'porpoise', '.']\n",
    ">>> all(len(w) > 4 for w in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> sent = ['No', 'good', 'fish', 'goes', 'anywhere', 'without', 'a', 'porpoise', '.']\n",
    ">>> any(len(w) > 4 for w in sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2   Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have seen two kinds of sequence object: strings and lists. Another kind of sequence is called a tuple. Tuples are formed with the comma operator, and typically enclosed using parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('walk', 'fem', 3)\n",
      "walk\n",
      "('fem', 3)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    ">>> t = 'walk', 'fem', 3\n",
    ">>> print (t)\n",
    ">>> print (t[0])\n",
    ">>> print (t[1:])\n",
    ">>> print (len(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare strings, lists and tuples directly, and do the indexing, slice, and length operation on each type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t', 'the', 'turned')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> raw = 'I turned off the spectroroute'\n",
    ">>> text = ['I', 'turned', 'off', 'the', 'spectroroute']\n",
    ">>> pair = (6, 'turned')\n",
    ">>> raw[2], text[3], pair[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ute', ['off', 'the', 'spectroroute'], (6, 'turned'))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> raw[-3:], text[-3:], pair[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 5, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> len(raw), len(text), len(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating on Sequence Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can iterate over the items in a sequence s in a variety of useful ways.\n",
    "\n",
    "We can convert between these sequence types. For example, tuple(s) converts any kind of sequence into a tuple, and list(s) converts any kind of sequence into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', '.', 'Red', 'lorry', 'red', 'yellow']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> import nltk\n",
    ">>> raw = 'Red lorry, yellow lorry, red lorry, yellow lorry.'\n",
    ">>> text = nltk.word_tokenize(raw)\n",
    ">>> fdist = nltk.FreqDist(text)\n",
    ">>> sorted(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.probability.FreqDist"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 3, '.': 1, 'Red': 1, 'lorry': 4, 'red': 1, 'yellow': 2})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red: 1; lorry: 4; ,: 3; yellow: 2; red: 1; .: 1; "
     ]
    }
   ],
   "source": [
    ">>> for key in fdist:\n",
    "...     print(key + ':', fdist[key], end='; ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'turned', 'the', 'spectroroute', 'off']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we use tuples to re-arrange the contents of our list.\n",
    ">>> words = ['I', 'turned', 'off', 'the', 'spectroroute']\n",
    ">>> words[2], words[3], words[4] = words[3], words[4], words[2]\n",
    ">>> words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x109f87088>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zip() takes the items of two or more sequences and \"zips\" them together into a single list of tuples.\n",
    ">>> words = ['I', 'turned', 'off', 'the', 'spectroroute']\n",
    ">>> tags = ['noun', 'verb', 'prep', 'det', 'noun']\n",
    ">>> zip(words, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'noun'),\n",
       " ('turned', 'verb'),\n",
       " ('off', 'prep'),\n",
       " ('the', 'det'),\n",
       " ('spectroroute', 'noun')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> list(zip(words, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'I'), (1, 'turned'), (2, 'off'), (3, 'the'), (4, 'spectroroute')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> list(enumerate(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we might want to \"train\" a system on 90% of the data and test it on the remaining 10%. \n",
    ">>> text = nltk.corpus.nps_chat.words()\n",
    ">>> cut = int(0.9 * len(text))\n",
    ">>> training_data, test_data = text[:cut], text[cut:]\n",
    ">>> text == training_data + test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40509\n",
      "4501\n",
      "45010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> print (len(training_data))\n",
    ">>> print (len(test_data))\n",
    ">>> print (len(text))\n",
    ">>> len(training_data) / len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Different Sequence Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I off the turned spectroroute'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> words = 'I turned off the spectroroute'.split()\n",
    ">>> wordlens = [(len(word), word) for word in words]\n",
    ">>> wordlens.sort()\n",
    ">>> ' '.join(w for (_, w) in wordlens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('off', 'prep', ['Qf', 'O:f'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> lexicon = [\n",
    "...     ('the', 'det', ['Di:', 'D@']),\n",
    "...     ('off', 'prep', ['Qf', 'O:f'])\n",
    "... ]\n",
    ">>> lexicon[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('turned', 'VBD', ['t3:nd', 't3`nd'])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Python, lists are mutable, while tuples are immutable. In other words, lists can be modified, while tuples cannot.\n",
    ">>> lexicon.sort()\n",
    ">>> lexicon[1] = ('turned', 'VBD', ['t3:nd', 't3`nd'])\n",
    ">>> lexicon[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('turned', 'VBD', ['t3:nd', 't3`nd'])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> lexicon = tuple(lexicon)\n",
    ">>> lexicon[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> lexicon[1] = ('turned', 'VBD', ['t3:nd', 't3`nd'])\n",
    "# >>> lexicon[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['``',\n",
       " 'when',\n",
       " 'i',\n",
       " 'use',\n",
       " 'a',\n",
       " 'word',\n",
       " ',',\n",
       " \"''\",\n",
       " 'humpty',\n",
       " 'dumpty',\n",
       " 'said',\n",
       " 'in',\n",
       " 'rather',\n",
       " 'a',\n",
       " 'scornful',\n",
       " 'tone',\n",
       " ',',\n",
       " \"''\",\n",
       " 'it',\n",
       " 'means',\n",
       " 'just',\n",
       " 'what',\n",
       " 'i',\n",
       " 'choose',\n",
       " 'it',\n",
       " 'to',\n",
       " 'mean',\n",
       " '-',\n",
       " 'neither',\n",
       " 'more',\n",
       " 'nor',\n",
       " 'less',\n",
       " '.',\n",
       " \"''\"]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> text = '''\"When I use a word,\" Humpty Dumpty said in rather a scornful tone,\n",
    "... \"it means just what I choose it to mean - neither more nor less.\"'''\n",
    ">>> [w.lower() for w in nltk.word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> max([w.lower() for w in nltk.word_tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['``',\n",
       " 'when',\n",
       " 'i',\n",
       " 'use',\n",
       " 'a',\n",
       " 'word',\n",
       " ',',\n",
       " \"''\",\n",
       " 'humpty',\n",
       " 'dumpty',\n",
       " 'said',\n",
       " 'in',\n",
       " 'rather',\n",
       " 'a',\n",
       " 'scornful',\n",
       " 'tone',\n",
       " ',',\n",
       " \"''\",\n",
       " 'it',\n",
       " 'means',\n",
       " 'just',\n",
       " 'what',\n",
       " 'i',\n",
       " 'choose',\n",
       " 'it',\n",
       " 'to',\n",
       " 'mean',\n",
       " '-',\n",
       " 'neither',\n",
       " 'more',\n",
       " 'nor',\n",
       " 'less',\n",
       " '.',\n",
       " \"''\"]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.lower() for w in nltk.word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This uses a generator expression.\n",
    ">>> max(w.lower() for w in nltk.word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x10a04b150>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(w.lower() for w in nltk.word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3   Questions of Style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Coding Style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code layout should use four spaces per indentation level. You should make sure that when you write Python code in a file, you avoid tabs for indentation, since these can be misinterpreted by different text editors and the indentation can be messed up. Lines should be less than 80 characters long; if necessary you can break a line inside parentheses, brackets, or braces, because Python is able to detect that the line continues over to the next line. If you need to break a line outside parentheses, brackets, or braces, you can often add extra parentheses, and you can always add a backslash at the end of the line that is broken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> syllables = 'Python Programming'\n",
    ">>> if (len(syllables) > 4 and len(syllables[2]) == 3 and\n",
    "...    syllables[2][2] in [aeiou] and syllables[2][3] == syllables[1][3]):\n",
    "...     process(syllables)\n",
    ">>> if len(syllables) > 4 and len(syllables[2]) == 3 and \\\n",
    "...    syllables[2][2] in [aeiou] and syllables[2][3] == syllables[1][3]:\n",
    "...     process(syllables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedural vs Declarative Style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Procedural style ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.401545438271973"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    ">>> tokens = nltk.corpus.brown.words(categories='news')\n",
    ">>> count = 0\n",
    ">>> total = 0\n",
    ">>> for token in tokens:\n",
    "...     count += 1\n",
    "...     total += len(token)\n",
    ">>> total / count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Declarative style ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.401545438271973\n",
      "442593\n",
      "100554\n"
     ]
    }
   ],
   "source": [
    "# The first line uses a generator expression to sum the token lengths, while the second line computes the average as before.\n",
    ">>> tokens = nltk.corpus.brown.words(categories='news')\n",
    ">>> total = sum(len(t) for t in tokens)\n",
    ">>> print(total / len(tokens))\n",
    ">>> print(total)\n",
    ">>> print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedural\n",
    "#>>> word_list = []\n",
    "#>>> i = 0\n",
    "#>>> while i < len(tokens):\n",
    "#...     j = 0\n",
    "#...     while j < len(word_list) and word_list[j] <= tokens[i]:\n",
    "#...         j += 1\n",
    "#...     if j == 0 or tokens[i] != word_list[j-1]:\n",
    "#...         word_list.insert(j, tokens[i])\n",
    "#...     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declarative\n",
    ">>> word_list = sorted(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1   5.40% the\n",
      "  2  10.42% ,\n",
      "  3  14.67% .\n",
      "  4  17.78% of\n",
      "  5  20.19% and\n",
      "  6  22.40% to\n",
      "  7  24.29% a\n",
      "  8  25.97% in\n"
     ]
    }
   ],
   "source": [
    ">>> fd = nltk.FreqDist(nltk.corpus.brown.words())\n",
    ">>> cumulative = 0.0\n",
    ">>> most_common_words = [word for (word, count) in fd.most_common()]\n",
    ">>> for rank, word in enumerate(most_common_words):\n",
    "...     cumulative += fd.freq(word)\n",
    "...     print(\"%3d %6.2f%% %s\" % (rank + 1, cumulative * 100, word))\n",
    "...     if cumulative > 0.25:\n",
    "...         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unextinguishable'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> text = nltk.corpus.gutenberg.words('milton-paradise.txt')\n",
    ">>> longest = ''\n",
    ">>> for word in text:\n",
    "...     if len(word) > len(longest):\n",
    "...         longest = word\n",
    ">>> longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> maxlen = max(len(word) for word in text)\n",
    ">>> maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unextinguishable',\n",
       " 'transubstantiate',\n",
       " 'inextinguishable',\n",
       " 'incomprehensible']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> [word for word in text if len(word) == maxlen]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Legitimate Uses for Counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'dog', 'gave'],\n",
       " ['dog', 'gave', 'John'],\n",
       " ['gave', 'John', 'the'],\n",
       " ['John', 'the', 'newspaper']]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    ">>> n = 3\n",
    ">>> [sent[i:i+n] for i in range(len(sent)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[set(), set(), set(), set(), set(), set(), set()],\n",
      " [set(), set(), set(), set(), set(), set(), set()],\n",
      " [set(), set(), set(), set(), set(), {'Alice'}, set()]]\n"
     ]
    }
   ],
   "source": [
    ">>> import pprint\n",
    ">>> m, n = 3, 7\n",
    ">>> array = [[set() for i in range(n)] for j in range(m)]\n",
    ">>> array[2][5].add('Alice')\n",
    ">>> pprint.pprint(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{7}, {7}, {7}, {7}, {7}, {7}, {7}],\n",
      " [{7}, {7}, {7}, {7}, {7}, {7}, {7}],\n",
      " [{7}, {7}, {7}, {7}, {7}, {7}, {7}]]\n"
     ]
    }
   ],
   "source": [
    ">>> array = [[set()] * n] * m\n",
    ">>> array[2][5].add(7)\n",
    ">>> pprint.pprint(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4   Functions: The Foundation of Structured Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def get_text(file):\n",
    "    \"\"\"Read text from a file, normalizing whitespace and stripping HTML markup.\"\"\"\n",
    "    text = open(file).read()\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function get_text in module __main__:\n",
      "\n",
      "get_text(file)\n",
      "    Read text from a file, normalizing whitespace and stripping HTML markup.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The first string inside a function definition is called a docstring. Not only does it document the purpose of the function to someone reading the code, it is accessible to a programmer who has loaded the code from a file:\n",
    "help(get_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python Monty Python Monty Python'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> def repeat(msg, num):\n",
    "...     return ' '.join([msg] * num)\n",
    ">>> monty = 'Monty Python'\n",
    ">>> repeat(monty, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> def monty():\n",
    "...     return \"Monty Python\"\n",
    ">>> monty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python Monty Python Monty Python'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> repeat(monty(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python Monty Python Monty Python'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> repeat('Monty Python', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> def my_sort1(mylist):      # good: modifies its argument, no return value\n",
    "...     mylist.sort()\n",
    ">>> def my_sort2(mylist):      # good: doesn't touch its argument, returns value\n",
    "...     return sorted(mylist)\n",
    ">>> def my_sort3(mylist):      # bad: modifies its argument and also returns it\n",
    "...     mylist.sort()\n",
    "...     return mylist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Python function is not required to have a return statement. Some functions do their work as a side effect, printing a result, modifying a file, or updating the contents of a parameter to the function (such functions are called \"procedures\" in some other programming languages)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Passing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python interprets function parameters as values (this is known as call-by-value). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['noun']\n"
     ]
    }
   ],
   "source": [
    ">>> def set_up(word, properties):\n",
    "...     word = 'lolcat'\n",
    "...     properties.append('noun')\n",
    "...     properties = 5\n",
    ">>> w = ''\n",
    ">>> p = []\n",
    ">>> set_up(w, p)\n",
    ">>> print (w)\n",
    ">>> print (p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that w was not changed by the function. When we called set_up(w, p), the value of w (an empty string) was assigned to a new variable word. Inside the function, the value of word was modified. However, that change did not propagate to w."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we called set_up(w, p), the value of p (a reference to an empty list) was assigned to a new local variable properties, so both variables now reference the same memory location. The function modifies properties, and this change is also reflected in the value of p as we saw. The function also assigned a new value to properties (the number 5); this did not modify the contents at that memory location, but created a new local variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you refer to an existing name from within the body of a function, the Python interpreter first tries to resolve the name with respect to the names that are local to the function. If nothing is found, the interpreter checks if it is a global name within the module. Finally, if that does not succeed, the interpreter checks if the name is a Python built-in. This is the so-called LGB rule of name resolution: local, then global, then built-in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Parameter Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python does not allow us to declare the type of a variable when we write a program, and this permits us to define functions that are flexible about the type of their arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> def tag(word):\n",
    "...     if word in ['a', 'the', 'all']:\n",
    "...         return 'det'\n",
    "...     else:\n",
    "...         return 'noun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'det'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> tag('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> tag('knight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> tag([\"'Tis\", 'but', 'a', 'scratch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive approach would be to check the type of the argument using if not type(word) is str, and if word is not a string, to simply return Python's special empty value, None. Here's a better solution, using an assert statement together with Python's basestring type that generalizes over both unicode and str. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#>>> def tag(word):\n",
    "#...     assert isinstance(word, str), \"argument to tag() must be a string\"\n",
    "#...     if word in ['a', 'the', 'all']:\n",
    "#...         return 'det'\n",
    "#...     else:\n",
    "#...         return 'noun'\n",
    "#>>> tag([\"'Tis\", 'but', 'a', 'scratch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well-structured programs usually make extensive use of functions. When a block of program code grows longer than 10-20 lines, it is a great help to readability if the code is broken up into one or more functions, each one having a clear purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def freq_words(url, freqdist, n):\n",
    "    html = request.urlopen(url).read().decode('utf8')\n",
    "    raw = BeautifulSoup(html).get_text()\n",
    "    for word in nltk.word_tokenize(raw):\n",
    "        freqdist[word.lower()] += 1\n",
    "    result = []\n",
    "    for word, count in freqdist.most_common(n):\n",
    "        result = result + [word]\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"''\", ',', 'the', ':', ':1', ';', '{', '}', 'of', '(', ')', 'archives', '#', \"'\", '.', 'national', 'and', '[', ']', '``', 'a', 'constitution', 'documents', 'to', 'declaration', '.section-theme', 'rights', 'charters', 'freedom', 'founding']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    ">>> constitution = \"http://www.archives.gov/exhibits/charters/constitution_transcript.html\"\n",
    ">>> fd = nltk.FreqDist()\n",
    ">>> freq_words(constitution, fd, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def freq_words(url, n):\n",
    "    html = request.urlopen(url).read().decode('utf8')\n",
    "    text = BeautifulSoup(html).get_text()\n",
    "    freqdist = nltk.FreqDist(word.lower() for word in nltk.word_tokenize(text))\n",
    "    return [word for (word, _) in fd.most_common(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"''\",\n",
       " ',',\n",
       " 'the',\n",
       " ':',\n",
       " ':1',\n",
       " ';',\n",
       " '{',\n",
       " '}',\n",
       " 'of',\n",
       " '(',\n",
       " ')',\n",
       " 'archives',\n",
       " '#',\n",
       " \"'\",\n",
       " '.',\n",
       " 'national',\n",
       " 'and',\n",
       " '[',\n",
       " ']',\n",
       " '``',\n",
       " 'a',\n",
       " 'constitution',\n",
       " 'documents',\n",
       " 'to',\n",
       " 'declaration',\n",
       " '.section-theme',\n",
       " 'rights',\n",
       " 'charters',\n",
       " 'freedom',\n",
       " 'founding']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> freq_words(constitution, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documenting Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the simplest functions, a one-line docstring is usually adequate. Docstrings can include a doctest block, illustrating the use of the function and the expected output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(reference, test):\n",
    "    \"\"\"\n",
    "    Calculate the fraction of test items that equal the corresponding reference items.\n",
    "\n",
    "    Given a list of reference values and a corresponding list of test values,\n",
    "    return the fraction of corresponding values that are equal.\n",
    "    In particular, return the fraction of indexes\n",
    "    {0<i<=len(test)} such that C{test[i] == reference[i]}.\n",
    "\n",
    "        >>> accuracy(['ADJ', 'N', 'V', 'N'], ['N', 'N', 'V', 'ADJ'])\n",
    "        0.5\n",
    "\n",
    "    :param reference: An ordered list of reference values\n",
    "    :type reference: list\n",
    "    :param test: A list of values to compare against the corresponding\n",
    "        reference values\n",
    "    :type test: list\n",
    "    :return: the accuracy score\n",
    "    :rtype: float\n",
    "    :raises ValueError: If reference and length do not have the same length\n",
    "    \"\"\"\n",
    "\n",
    "    if len(reference) != len(test):\n",
    "        raise ValueError(\"Lists must have the same length.\")\n",
    "    num_correct = 0\n",
    "    for x, y in zip(reference, test):\n",
    "        if x == y:\n",
    "            num_correct += 1\n",
    "    return float(num_correct) / len(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "accuracy() missing 2 required positional arguments: 'reference' and 'test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-2dfa93d7db72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: accuracy() missing 2 required positional arguments: 'reference' and 'test'"
     ]
    }
   ],
   "source": [
    "accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(['ADJ', 'N', 'V', 'N'], ['N', 'N', 'V', 'ADJ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5   Doing More with Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions as Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 2, 3, 5, 1, 3, 3, 6, 4, 4, 4, 2, 10, 1]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> sent = ['Take', 'care', 'of', 'the', 'sense', ',', 'and', 'the',\n",
    "...         'sounds', 'will', 'take', 'care', 'of', 'themselves', '.']\n",
    ">>> def extract_property(prop):\n",
    "...     return [prop(word) for word in sent]\n",
    ">>> extract_property(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'e', 'f', 'e', 'e', ',', 'd', 'e', 's', 'l', 'e', 'e', 'f', 's', '.']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> def last_letter(word):\n",
    "...     return word[-1]\n",
    ">>> extract_property(last_letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Python provides us with one more way to define functions as arguments to other functions, so-called lambda expressions.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'e', 'f', 'e', 'e', ',', 'd', 'e', 's', 'l', 'e', 'e', 'f', 's', '.']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> extract_property(lambda w: w[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 2, 3, 5, 1, 3, 3, 6, 4, 4, 4, 2, 10, 1]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> extract_property(lambda w: len(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#>>> sorted(sent)\n",
    "#>>> sorted(sent, cmp())\n",
    "#>>> sorted(sent, lambda x, y: cmp(len(y), len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accumulative Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search1(substring, words):\n",
    "    result = []\n",
    "    for word in words:\n",
    "        if substring in word:\n",
    "            result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The function search2() is a generator. The first time this function is called, \n",
    "# it gets as far as the yield statement and pauses. The calling program gets the first word and \n",
    "# does any necessary processing. Once the calling program is ready for another word, \n",
    "# execution of the function is continued from where it stopped, until the next time it encounters a yield statement. \n",
    "def search2(substring, words):\n",
    "    for word in words:\n",
    "        if substring in word:\n",
    "            yield word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grizzlies' fizzled Rizzuto huzzahs dazzler jazz Pezza Pezza Pezza embezzling embezzlement pizza jazz Ozzie nozzle drizzly puzzle puzzle dazzling Sizzling guzzle puzzles dazzling jazz jazz Jazz jazz Jazz jazz jazz Jazz jazz jazz jazz Jazz jazz dizzy jazz Jazz puzzler jazz jazzmen jazz jazz Jazz Jazz Jazz jazz Jazz jazz jazz jazz Jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz Jazz Jazz jazz jazz nozzles nozzle puzzle buzz puzzle blizzard blizzard sizzling puzzled puzzle puzzle muzzle muzzle muezzin blizzard Neo-Jazz jazz muzzle piazzas puzzles puzzles embezzle buzzed snazzy buzzes puzzled puzzled muzzle whizzing jazz Belshazzar Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie's Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie blizzard blizzards blizzard blizzard fuzzy Lazzeri Piazza piazza palazzi Piazza Piazza Palazzo Palazzo Palazzo Piazza Piazza Palazzo palazzo palazzo Palazzo Palazzo Piazza piazza piazza piazza Piazza Piazza Palazzo palazzo Piazza piazza pizza Piazza Palazzo palazzo dazzling puzzling Wozzek dazzling dazzling buzzing Jazz jazz Jazz Jazz jazz jazz jazz jazz Jazz jazz jazz jazz Fuzzy Lizzy Lizzy jazz fuzzy puzzles puzzling puzzling dazzle puzzle dazzling puzzled jazz jazz jazz jazzy whizzed frazzled quizzical puzzling poetry-and-jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz Jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz Dizzy jazz jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz dazzled bedazzlement bedazzled Piazzo nozzles nozzles buzzing dazzles dizzy puzzling puzzling puzzling puzzle muzzle puzzled nozzle Pozzatti Pozzatti Pozzatti puzzled Pozzatti Pozzatti dazzling pizzicato Jazz jazz jazz jazz jazz nozzle grizzled fuzzy muzzle puzzled puzzle muzzle blizzard buzz dizzily drizzle drizzle drizzle sizzled puzzled puzzled puzzled fuzzed buzz buzz buzz buzz-buzz-buzz buzzes fuzzy frizzled drizzle drizzle drizzling drizzling fuzz jazz jazz fuzz puzzle puzzling Nozze mezzo puzzled puzzled dazzling muzzle muzzle muzzle buzzed whizzed sizzled palazzos puzzlement frizzling puzzled puzzled puzzled dazzling muzzles fuzzy jazz ex-jazz sizzle grizzly guzzled buzzing fuzz nuzzled Kizzie Kizzie Kizzie Kezziah Kizzie Kizzie Buzz's Buzz Buzz Buzz Buzz Buzz Buzz Buzz Buzz dizzy piazza buzzing Puzzled dizziness dazzled Piazza Carrozza fuzzy dizzy buzzing buzzing puzzled puzzling puzzled puzzled Quizzical pizza "
     ]
    }
   ],
   "source": [
    ">>> for item in search1('zz', nltk.corpus.brown.words()):\n",
    "...     print(item, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grizzlies' fizzled Rizzuto huzzahs dazzler jazz Pezza Pezza Pezza embezzling embezzlement pizza jazz Ozzie nozzle drizzly puzzle puzzle dazzling Sizzling guzzle puzzles dazzling jazz jazz Jazz jazz Jazz jazz jazz Jazz jazz jazz jazz Jazz jazz dizzy jazz Jazz puzzler jazz jazzmen jazz jazz Jazz Jazz Jazz jazz Jazz jazz jazz jazz Jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz Jazz Jazz jazz jazz nozzles nozzle puzzle buzz puzzle blizzard blizzard sizzling puzzled puzzle puzzle muzzle muzzle muezzin blizzard Neo-Jazz jazz muzzle piazzas puzzles puzzles embezzle buzzed snazzy buzzes puzzled puzzled muzzle whizzing jazz Belshazzar Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie's Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie blizzard blizzards blizzard blizzard fuzzy Lazzeri Piazza piazza palazzi Piazza Piazza Palazzo Palazzo Palazzo Piazza Piazza Palazzo palazzo palazzo Palazzo Palazzo Piazza piazza piazza piazza Piazza Piazza Palazzo palazzo Piazza piazza pizza Piazza Palazzo palazzo dazzling puzzling Wozzek dazzling dazzling buzzing Jazz jazz Jazz Jazz jazz jazz jazz jazz Jazz jazz jazz jazz Fuzzy Lizzy Lizzy jazz fuzzy puzzles puzzling puzzling dazzle puzzle dazzling puzzled jazz jazz jazz jazzy whizzed frazzled quizzical puzzling poetry-and-jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz Jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz Dizzy jazz jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz dazzled bedazzlement bedazzled Piazzo nozzles nozzles buzzing dazzles dizzy puzzling puzzling puzzling puzzle muzzle puzzled nozzle Pozzatti Pozzatti Pozzatti puzzled Pozzatti Pozzatti dazzling pizzicato Jazz jazz jazz jazz jazz nozzle grizzled fuzzy muzzle puzzled puzzle muzzle blizzard buzz dizzily drizzle drizzle drizzle sizzled puzzled puzzled puzzled fuzzed buzz buzz buzz buzz-buzz-buzz buzzes fuzzy frizzled drizzle drizzle drizzling drizzling fuzz jazz jazz fuzz puzzle puzzling Nozze mezzo puzzled puzzled dazzling muzzle muzzle muzzle buzzed whizzed sizzled palazzos puzzlement frizzling puzzled puzzled puzzled dazzling muzzles fuzzy jazz ex-jazz sizzle grizzly guzzled buzzing fuzz nuzzled Kizzie Kizzie Kizzie Kezziah Kizzie Kizzie Buzz's Buzz Buzz Buzz Buzz Buzz Buzz Buzz Buzz dizzy piazza buzzing Puzzled dizziness dazzled Piazza Carrozza fuzzy dizzy buzzing buzzing puzzled puzzling puzzled puzzled Quizzical pizza "
     ]
    }
   ],
   "source": [
    ">>> for item in search2('zz', nltk.corpus.brown.words()):\n",
    "...     print(item, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a more sophisticated example of a generator which produces all permutations of a list of words. In order to force the permutations() function to generate all its output, we wrap it with a call to list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['police', 'fish', 'buffalo'],\n",
       " ['fish', 'police', 'buffalo'],\n",
       " ['fish', 'buffalo', 'police'],\n",
       " ['police', 'buffalo', 'fish'],\n",
       " ['buffalo', 'police', 'fish'],\n",
       " ['buffalo', 'fish', 'police']]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The ability to generate permutations of a set of words is useful for creating data to test a grammar\n",
    ">>> def permutations(seq):\n",
    "...     if len(seq) <= 1:\n",
    "...         yield seq\n",
    "...     else:\n",
    "...         for perm in permutations(seq[1:]):\n",
    "...             for i in range(len(perm)+1):\n",
    "...                 yield perm[:i] + seq[0:1] + perm[i:]\n",
    "...\n",
    ">>> list(permutations(['police', 'fish', 'buffalo']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higher-Order Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Take', 'care', 'sense', 'sounds', 'take', 'care', 'themselves']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> def is_content_word(word):\n",
    "...     return word.lower() not in ['a', 'of', 'the', 'and', 'will', ',', '.']\n",
    ">>> sent = ['Take', 'care', 'of', 'the', 'sense', ',', 'and', 'the',\n",
    "...         'sounds', 'will', 'take', 'care', 'of', 'themselves', '.']\n",
    ">>> list(filter(is_content_word, sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Take', 'care', 'sense', 'sounds', 'take', 'care', 'themselves']"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> [w for w in sent if is_content_word(w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<filter at 0x10a706588>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter(is_content_word, sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.75081116158339"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> lengths = list(map(len, nltk.corpus.brown.sents(categories='news')))\n",
    ">>> sum(lengths) / len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.75081116158339"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> lengths = [len(sent) for sent in nltk.corpus.brown.sents(categories='news')]\n",
    ">>> sum(lengths) / len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'filter' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-208-6e97bb79b830>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m\"aeiou\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-208-6e97bb79b830>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(w)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m\"aeiou\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'filter' has no len()"
     ]
    }
   ],
   "source": [
    ">>> list(map(lambda w: len(filter(lambda c: c.lower() in \"aeiou\", w)), sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'generator' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-209-a36bad69c986>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m\"aeiou\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-209-a36bad69c986>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m\"aeiou\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'generator' has no len()"
     ]
    }
   ],
   "source": [
    ">>> [len(c for c in w if c.lower() in \"aeiou\") for w in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> def repeat(msg='<empty>', num=1):\n",
    "...     return msg * num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<empty><empty><empty>'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> repeat(num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> repeat(msg='Alice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AliceAliceAliceAliceAlice'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> repeat(num=5, msg='Alice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are called **keyword arguments**. If we mix these two kinds of parameters, then we must ensure that the unnamed parameters precede the named ones. It has to be this way, since unnamed parameters are defined by position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a function that takes an arbitrary number of unnamed and named parameters, and access them via an in-place list of arguments *args and an \"in-place dictionary\" of keyword arguments **kwargs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> def generic(*args, **kwargs):\n",
    "...     print(args)\n",
    "...     print(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'African swallow')\n",
      "{'monty': 'python'}\n"
     ]
    }
   ],
   "source": [
    ">>> generic(1, \"African swallow\", monty=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When *args appears as a function parameter, it actually corresponds to all the unnamed parameters of the function. Here's another illustration of this aspect of Python syntax, for the zip() function which operates on a variable number of arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> def freq_words(file, min=1, num=10):\n",
    "...     text = open(file).read()\n",
    "...     tokens = nltk.word_tokenize(text)\n",
    "...     freqdist = nltk.FreqDist(t for t in tokens if len(t) >= min)\n",
    "...     return freqdist.most_common(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('fascinating', 1), ('learn', 1), ('NLTK', 1)]\n",
      "[('fascinating', 1), ('learn', 1), ('NLTK', 1)]\n",
      "[('fascinating', 1), ('learn', 1), ('NLTK', 1)]\n"
     ]
    }
   ],
   "source": [
    ">>> fw1 = freq_words('file.txt', 4, 10)\n",
    ">>> print (fw1)\n",
    ">>> fw2 = freq_words('file.txt', min=4, num=10)\n",
    ">>> print (fw2)\n",
    ">>> fw3 = freq_words('file.txt', num=10, min=4)\n",
    ">>> print (fw3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> def freq_words(file, min=1, num=10, verbose=False):\n",
    "...     freqdist = FreqDist()\n",
    "...     if verbose: print(\"Opening\", file)\n",
    "...     text = open(file).read()\n",
    "...     if verbose: print(\"Read in %d characters\" % len(file))\n",
    "...     for word in word_tokenize(text):\n",
    "...         if len(word) >= min:\n",
    "...             freqdist[word] += 1\n",
    "...             if verbose and freqdist.N() % 100 == 0: print(\".\", sep=\"\")\n",
    "...     if verbose: print\n",
    "...     return freqdist.most_common(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is fascinating to learn NLTK\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Python will close open files automatically if you use the with statement:\n",
    ">>> with open(\"file.txt\") as f:\n",
    "...     data = f.read()\n",
    ">>> print (data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6   Program Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programming is a skill that is acquired over several years of experience with a variety of programming languages and tasks. \n",
    "\n",
    "Key high-level abilities are algorithm design and its manifestation in structured programming. \n",
    "\n",
    "Key low-level abilities include familiarity with the syntactic constructs of the language, and knowledge of a variety of diagnostic methods for trouble-shooting a program which does not exhibit the expected behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of a Python Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of a program module is to bring logically-related definitions and functions together in order to facilitate re-use and abstraction. Python modules are nothing more than individual .py files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can locate the code for any NLTK module on your system using the __file__ variable\n",
    "# >>> nltk.metrics.distance.__file__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Some module variables and functions are only used within the module. These should have names beginning with an underscore, e.g. _helper(), since this will hide the name. If another module imports this one, using the idiom: from module import *, these names will not be imported. You can optionally list the externally accessible names of a module using a special built-in variable like this: __all__ = ['edit_distance', 'jaccard_distance']. ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Module Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure of a Multi-Module Program: The main program my_program.py imports functions from two other modules; unique analysis tasks are localized to the main program, while common loading and visualization tasks are kept apart to facilitate re-use and abstraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources of Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debugging code is hard because there are so many ways for it to be faulty.\n",
    "\n",
    "First, the input data may contain some unexpected characters.\n",
    "\n",
    "Second, a supplied function might not behave as expected.\n",
    "\n",
    "Third, our understanding of Python's semantics may be at fault."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging Techniques\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python provides a debugger which allows you to monitor the execution of your program, specify line numbers where execution will stop (i.e. breakpoints), and step through sections of code and inspect the value of variables. You can invoke the debugger on your code as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> import pdb\n",
    "# >>> import mymodule\n",
    "# >>> pdb.run('mymodule.myfunction()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will present you with a prompt (Pdb) where you can type instructions to the debugger. Type help to see the full list of commands. Typing step (or just s) will execute the current line and stop. If the current line calls a function, it will enter the function and stop at the first line. Typing next (or just n) is similar, but it stops execution at the next line in the current function. The break (or  b) command can be used to create or list breakpoints. Type continue (or c) to continue execution as far as the next breakpoint. Type the name of any variable to inspect its value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defensive Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid some of the pain of debugging, it helps to adopt some defensive programming habits. Instead of writing a 20-line program then testing it, build the program bottom-up out of small pieces that are known to work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you develop your program, extend its functionality, and fix any bugs, it helps to maintain a suite of test cases. This is called regression testing, since it is meant to detect situations where the code \"regresses\" — where a change to the code has an unintended side-effect of breaking something that used to work. Python provides a simple regression testing framework in the form of the  doctest module. This module searches a file of code or documentation for blocks of text that look like an interactive Python session, of the form you have already seen many times in this book. It executes the Python commands it finds, and tests that their output matches the output supplied in the original file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the most important defensive programming strategy is to set out your code clearly, choose meaningful variable and function names, and simplify the code wherever possible by decomposing it into functions and modules with well-documented interfaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7   Algorithm Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A major part of algorithmic problem solving is selecting or adapting an appropriate algorithm for the problem at hand. Sometimes there are several alternatives, and choosing the best one depends on knowledge about how each alternative performs as the size of the data grows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best known strategy is known as divide-and-conquer. We attack a problem of size n by dividing it into two problems of size n/2, solve these problems, and combine their results into a solution of the original problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above examples of sorting and searching have a striking property: to solve a problem of size n, we have to break it in half and then work on one or more problems of size n/2. A common way to implement such methods uses recursion. We define a function f which simplifies the problem, and calls itself to solve one or more easier instances of the same problem. It then combines the results into a solution for the original problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> def factorial1(n):\n",
    "...     result = 1\n",
    "...     for i in range(n):\n",
    "...         result *= (i+1)\n",
    "...     return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there is also a recursive algorithm for solving this problem, based on the following observation. Suppose we have a way to construct all orderings for n-1 distinct words. Then for each such ordering, there are n places where we can insert a new word: at the start, the end, or any of the n-2 boundaries between the words. Thus we simply multiply the number of solutions found for n-1 by the value of n. We also need the base case, to say that if we have a single word, there's just one ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> def factorial2(n):\n",
    "...     if n == 1:\n",
    "...         return 1\n",
    "...     else:\n",
    "...         return n * factorial2(n-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count the size of the hypernym hierarchy rooted at a given synset s. We'll do this by finding the size of each hyponym of s, then adding these together (we will also add 1 for the synset itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> def size1(s):\n",
    "...     return 1 + sum(size1(child) for child in s.hyponyms())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also design an iterative solution to this problem which processes the hierarchy in layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> def size2(s):\n",
    "...     layer = [s]\n",
    "...     total = 0\n",
    "...     while layer:\n",
    "...         total += len(layer)\n",
    "...         layer = [h for c in layer for h in c.hyponyms()] [3]\n",
    "...     return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'Synset' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-235-2dbca110af50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dog.n.01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msize1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msize2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-234-cf74ef367916>\u001b[0m in \u001b[0;36msize2\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyponyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'Synset' has no len()"
     ]
    }
   ],
   "source": [
    ">>> from nltk.corpus import wordnet as wn\n",
    ">>> dog = wn.synset('dog.n.01')\n",
    ">>> print (size1(dog))\n",
    ">>> print (size2(dog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Building a Letter Trie: A recursive function that builds a nested dictionary structure; each level of nesting contains all words with a given prefix, and a sub-trie containing all possible continuations.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### let's use it to construct a deeply-nested object.\n",
    "def insert(trie, key, value):\n",
    "    if key:\n",
    "        first, rest = key[0], key[1:]\n",
    "        if first not in trie:\n",
    "            trie[first] = {}\n",
    "        insert(trie[first], rest, value)\n",
    "    else:\n",
    "        trie['value'] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> trie = {}\n",
    ">>> insert(trie, 'chat', 'cat')\n",
    ">>> insert(trie, 'chien', 'dog')\n",
    ">>> insert(trie, 'chair', 'flesh')\n",
    ">>> insert(trie, 'chic', 'stylish')\n",
    ">>> trie = dict(trie)               # for nicer printing\n",
    ">>> trie['c']['h']['a']['t']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c': {'h': {'a': {'i': {'r': {'value': 'flesh'}},\n",
      "                   't': {'value': 'cat'}},\n",
      "             'i': {'c': {'value': 'stylish'},\n",
      "                   'e': {'n': {'value': 'dog'}}}}}}\n"
     ]
    }
   ],
   "source": [
    ">>> pprint.pprint(trie, width=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Space-Time Tradeoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sometimes significantly speed up the execution of a program by building an auxiliary data structure, such as an index. The listing in 4.10 implements a simple text retrieval system for the Movie Reviews Corpus. By indexing the document collection it provides much faster lookup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** A Simple Text Retrieval System ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Index...\n",
      "query> beautiful\n",
      "sure , she is one of the most beautiful creatures on god's g\n",
      "sure , she is one of the most beautiful creatures on god's g\n",
      "t half of the film is starkly beautiful . watching edgar rea\n",
      "ing foreign imports ( life is beautiful ) and freddie prinze\n",
      " of fiennes and dafoe and the beautiful desert cinematograph\n",
      " ) , who turns out to be more beautiful than those who are \"\n",
      " ) , who turns out to be more beautiful than those who are \"\n",
      "aculously , what comes out is beautiful . a group of onlooke\n",
      "om tv's friends ) , a smart , beautiful , professional woman\n",
      "interact with himself in such beautiful motions are built ar\n",
      "m to continue to live in this beautiful village and earn eno\n",
      "tion is illogical ) , and the beautiful , crisp cinematograp\n",
      "! where's joblo coming from ? beautiful ( 1/10 ) - my best f\n",
      "xchanging love letters with a beautiful woman , ashley ( cha\n",
      "l while enthusing \" move your beautiful big ass , \" the movi\n",
      "ed p . i . among the rich and beautiful whose glamour hides \n",
      " on a soap opera opposite the beautiful kelly ( daryl hannah\n",
      "ll ( jack johnson ) , and his beautiful scientist daughter j\n",
      " ! ! and , and , we must have beautiful scenic worldwide sho\n",
      "an whom patch makes laugh , a beautiful woman who can't love\n",
      "se-up of a human eye . it's a beautiful piece of work , rema\n",
      "st movie of the year so far , beautiful , this film also man\n",
      "ge too reminiscent of life is beautiful , but those scenes a\n",
      "e hollywood hills . dazed , a beautiful brunette ( laura ele\n",
      "he witnesses a mysterious and beautiful woman ( ashley judd \n",
      "y who eats all the time , the beautiful woman who doesn't be\n",
      "over $400 to mud wrestle five beautiful women , but while wa\n",
      "sanders' vet tambor . and the beautiful vivica a . fox has o\n",
      "e is wonderfully decorated -- beautiful , mysterious , magic\n",
      "enough to get your hands on a beautiful , kind girl , you sh\n",
      "enough to get your hands on a beautiful , kind girl , you sh\n",
      " its irony laden dialogue and beautiful ( though not overly \n",
      "ng romantic relationship with beautiful model anabelle ( lau\n",
      " a bigger production design , beautiful photography ( by aca\n",
      "hink they're smarter and more beautiful than all the other p\n",
      "hink they're smarter and more beautiful than all the other p\n",
      "e is wonderfully decorated -- beautiful , mysterious , magic\n",
      " marie celeste . aside from a beautiful jewel thief ( famke \n",
      "s a warm man in love with the beautiful wanda . having died \n",
      "ransformed into vylette , the beautiful \" new girl \" at scho\n",
      "n zero-gravity . the sets are beautiful to gaze upon . and r\n",
      "ked her photo and is actually beautiful . skipping a few mod\n",
      ", the woman just a little too beautiful to be living in such\n",
      "ared with last year's life is beautiful because it is being \n",
      "lf we've seen them in life is beautiful , you've got mail , \n",
      "lly , has other motives : the beautiful park ranger jesse ( \n",
      " who has written stuff like \" beautiful girls \" and \" things\n",
      "mountains that are absolutely beautiful . the second is the \n",
      "and showed that it wasn't all beautiful plantations , green \n",
      "ck up an additional helper- a beautiful hustler ( played by \n",
      " everything look a little too beautiful . do the offices of \n",
      "proved upon by sacha vierny's beautiful cinematography that \n",
      "k of real plot with a veil of beautiful people . in truth , \n",
      "y ? well , it teaches us that beautiful , attractive women w\n",
      "by helena ( sherilyn fenn ) , beautiful woman who ditched hi\n",
      "by helena ( sherilyn fenn ) , beautiful woman who ditched hi\n",
      "e where he sings \" you are so beautiful to me \" to a dragon-\n",
      "ter moments . and what is the beautiful lela rochon doing in\n",
      "y . this film was filled with beautiful african scenery . bu\n",
      "it did come off as dull , the beautiful cinematography is ey\n",
      " be like to be an angel . the beautiful camera work , shooti\n",
      "s favorite because she's both beautiful and kind . liz is ab\n",
      "dna scientist is pleasant and beautiful . natasha is an exqu\n",
      "s new wife turn out to be the beautiful julia ( jolie ) , sh\n",
      "ignment where he encounters a beautiful woman ( ashley judd \n",
      " to her again , showing her a beautiful pad that he built fr\n",
      " the beast copout of having a beautiful woman fall in love w\n",
      " the beast copout of having a beautiful woman fall in love w\n",
      "in dunn ) who raves about his beautiful hair . the explorers\n",
      "res baron harkonnen killing a beautiful young man in front o\n",
      " at a bar , he notices that a beautiful woman has left her p\n",
      "d dylan's obsessions with his beautiful new neighbour , lila\n",
      " a perfect life . they have a beautiful house in suburbia . \n",
      "rating their history is oddly beautiful and touching , but a\n",
      ", with its main asset being a beautiful film location along \n",
      "ally . sexual tension between beautiful female patron and sh\n",
      "e finds himself surrounded by beautiful women , driving a ne\n",
      "hloe ( marley shelton ) , the beautiful girl next door . jim\n",
      ". but no , they opted for the beautiful sunrise ending . tha\n",
      " is great- looking . it looks beautiful , but this is also a\n",
      " is great- looking . it looks beautiful , but this is also a\n",
      "eedy pornography shop , where beautiful models ( no , hooker\n",
      "eedy pornography shop , where beautiful models ( no , hooker\n",
      "eedy pornography shop , where beautiful models ( no , hooker\n",
      " are the completely bland but beautiful scientist linda ( el\n",
      "the idea of flirting with the beautiful sam makes jay so sic\n",
      "te , who falls in love with a beautiful woman ( gwyneth palt\n",
      "wise-ass . davis is radiantly beautiful , and keaton is gene\n",
      " crawford , arguably the most beautiful woman on the planet \n",
      "sely resembles the stunningly beautiful kari wuhrer , who pl\n",
      "ho live aboard the ship , the beautiful teenage girl and her\n",
      "ho live aboard the ship , the beautiful teenage girl and her\n",
      " takes great advantage of the beautiful eastern coast , and \n",
      "us another thriller , and the beautiful rachel stealing beau\n",
      "ter on a midnight swim with a beautiful girl that turns dead\n",
      "f the crew is erica , a young beautiful witch-wannabe , who \n",
      "katie holmes plays hannah , a beautiful , talented writing s\n",
      "katie holmes plays hannah , a beautiful , talented writing s\n",
      "t designing clothes -- that's beautiful and liberating , \" i\n",
      "o is played by the stirringly beautiful nandita das . ( she \n",
      "ical , awkward , moving , and beautiful . by including the v\n",
      "arving artist lusting after a beautiful woman from his child\n",
      "seemingly idyllic life in the beautiful town of seahaven . h\n",
      ". everything is ordinary--yet beautiful--in this film . >fro\n",
      "tration camps ? the movie was beautifully and sensitively ma\n",
      "nuelle beart's personality is beautiful . and needless to sa\n",
      "nuelle beart's personality is beautiful . and needless to sa\n",
      " superstar . she is radiantly beautiful and totally persuasi\n",
      "e transfer to dvd is rich and beautiful . x-mozilla-status :\n",
      "s neo-classic drama , life is beautiful . through a central \n",
      "s neo-classic drama , life is beautiful . through a central \n",
      "s neo-classic drama , life is beautiful . through a central \n",
      "s neo-classic drama , life is beautiful . through a central \n",
      "hin red line , is a strange , beautiful , enigmatic mess of \n",
      "hin red line , is a strange , beautiful , enigmatic mess of \n",
      " hooker , named vivian , is a beautiful , generally upbeat y\n",
      " and wonderful cast , and the beautiful scenery of vancouver\n",
      "y and staging of the film are beautiful to watch . the actio\n",
      "of your world \" , an achingly beautiful tune of yearning and\n",
      "caust . but benigni's life is beautiful ( la vita e bella ) \n",
      "caust . but benigni's life is beautiful ( la vita e bella ) \n",
      "caust . but benigni's life is beautiful ( la vita e bella ) \n",
      "or in search of the truth . a beautiful woman ( gretchen mol\n",
      "or in search of the truth . a beautiful woman ( gretchen mol\n",
      "or in search of the truth . a beautiful woman ( gretchen mol\n",
      "as sweet and caring as she is beautiful . she is totally dev\n",
      " lessons from the elegant and beautiful mai ( tamiyo kusakar\n",
      "ozart . technically this is a beautiful film and a lot of th\n",
      "ame to get the attention of a beautiful law office worker ( \n",
      "en up one night when he spots beautiful mai kishikawa ( tami\n",
      "opez . lopez is , of course , beautiful , but she can act , \n",
      " . computer chip . \" isn't it beautiful , \" she coos . a sho\n",
      "most startling images is of a beautiful woman with large sca\n",
      "an full of so many impossibly beautiful women it's no wonder\n",
      " there is something strangely beautiful about every shot in \n",
      " there is something strangely beautiful about every shot in \n",
      "she has learned that frances' beautiful and loving dog has b\n",
      "teen spirit . \" sumptuous and beautiful , vulgar and overdon\n",
      "ardboard cutout character . a beautiful film in its own drea\n",
      "ni ( daryl sabara ) live in a beautiful seaside home with th\n",
      "ually good , and paralyzingly beautiful ; she's also a stron\n",
      "always sit back and enjoy the beautiful computer animation ,\n",
      " her especially when he has a beautiful , intelligent writer\n",
      " her especially when he has a beautiful , intelligent writer\n",
      "eductive and repellent like a beautiful venomous snake . his\n",
      " that , sure enough , life is beautiful is in fact a comedy \n",
      " that , sure enough , life is beautiful is in fact a comedy \n",
      " that , sure enough , life is beautiful is in fact a comedy \n",
      " that , sure enough , life is beautiful is in fact a comedy \n",
      " that , sure enough , life is beautiful is in fact a comedy \n",
      " for drawing some of the most beautiful pictures that i have\n",
      " for drawing some of the most beautiful pictures that i have\n",
      " for drawing some of the most beautiful pictures that i have\n",
      " for drawing some of the most beautiful pictures that i have\n",
      "ew mexico and puerto rico are beautiful . the politics of fo\n",
      "eam . he wakes up next to his beautiful wife , played by sto\n",
      "eam . he wakes up next to his beautiful wife , played by sto\n",
      " for ourselves . a checkpoint beautiful kind of thing , and \n",
      " for ourselves . a checkpoint beautiful kind of thing , and \n",
      " whom i have heard ) create a beautifully realized piece of \n",
      ") who lives on earth with his beautiful wife lori ( sharon s\n",
      "roat hollywood party with the beautiful people or a 50s swin\n",
      "surance agent living with his beautiful wife meryl ( laura l\n",
      "asterpiece . this eqsuisite , beautiful film is a rare gem .\n",
      "of the same name . he rides a beautiful black steed and carr\n",
      "xt to martin or murphy is the beautiful heather graham , as \n",
      "e effect is sad , lyrical and beautiful . things get a littl\n",
      "use he falls in love with the beautiful daughter . there are\n",
      "ay . the first hour or so was beautifully done , not so much\n",
      "ow - and amazingly , it works beautifully . on my second vie\n",
      "farm life - - and experiences beautiful and wondrous things \n",
      "harts , with chiseled men and beautiful women . despite thes\n",
      "ween the women are especially beautiful . the musical score \n",
      "n . \" his attitude upsets his beautiful and increasing jealo\n",
      "ble for cronenbergto create a beautiful world where time , s\n",
      "ooking films i've ever seen , beautiful black and white phot\n",
      "ooking films i've ever seen , beautiful black and white phot\n",
      "ncredible palette of colors , beautiful sunrises , lush gold\n",
      "ncredible palette of colors , beautiful sunrises , lush gold\n",
      "ncredible palette of colors , beautiful sunrises , lush gold\n",
      "ncredible palette of colors , beautiful sunrises , lush gold\n",
      "ncredible palette of colors , beautiful sunrises , lush gold\n",
      "someone's mind are incredibly beautiful ( including the dank\n",
      "the way the film looks . it's beautiful and painstakingly cr\n",
      "ti-purpose cell phone ) , and beautiful women . enter michel\n",
      " humanity consists of young , beautiful , but idle eloi , pe\n",
      " eventually grows to become a beautiful , intelligent , and \n",
      "birthday , and then reveals a beautiful necklace he has also\n",
      "he new next door neighbor : a beautiful intelligent lively g\n",
      "he new next door neighbor : a beautiful intelligent lively g\n",
      "e he reaches oregon , land of beautiful women , bright young\n",
      "cannot accept that a woman as beautiful as vicki could be fa\n",
      "them to life on the screen in beautifully dramatic images , \n",
      "ment of its subject , and its beautiful technical specificat\n",
      " to her . she is successful , beautiful , and dates a well-k\n",
      "he epitome of your search . a beautiful cast , awesome speci\n",
      "terrific as the astonishingly beautiful actress , and grant \n",
      "terrific as the astonishingly beautiful actress , and grant \n",
      "ut its good natured charm and beautiful performances light u\n",
      "ut its good natured charm and beautiful performances light u\n",
      "oddly touching tragedy with a beautiful and uniquely hauntin\n",
      "oddly touching tragedy with a beautiful and uniquely hauntin\n",
      "i when you see that ? life is beautiful , even though i'm a \n",
      "i when you see that ? life is beautiful , even though i'm a \n",
      "i when you see that ? life is beautiful , even though i'm a \n",
      "i when you see that ? life is beautiful , even though i'm a \n",
      "i when you see that ? life is beautiful , even though i'm a \n",
      "i when you see that ? life is beautiful , even though i'm a \n",
      "i when you see that ? life is beautiful , even though i'm a \n",
      "i when you see that ? life is beautiful , even though i'm a \n",
      "i when you see that ? life is beautiful , even though i'm a \n",
      " in venice circa 1583 . it is beautifully filmed , wonderful\n",
      " williams again excels by his beautiful music , this time us\n",
      " a ranch out west and raise a beautiful family . then there \n",
      "a lot of fun and it carries a beautiful message of love and \n",
      "ctually acts , not just looks beautiful . however , the most\n",
      " : a great loving husband , a beautiful son and a great frie\n",
      " : a great loving husband , a beautiful son and a great frie\n",
      "nd featuring some elaborate , beautiful scenery . from the g\n",
      "film critic james agee does a beautiful job giving shape and\n",
      "an opera , where his achingly beautiful designs further the \n",
      "s in \" aladdin \" . the always beautiful cameron diaz gives t\n",
      "s in \" aladdin \" . the always beautiful cameron diaz gives t\n",
      "rst disc and has been given a beautiful transfer that shows \n",
      "raphr roger deakins created a beautiful world on film . perh\n",
      "raphr roger deakins created a beautiful world on film . perh\n",
      "ors and special effects , the beautiful setting of this movi\n",
      "tual music is both morose and beautiful . when she sings \" s\n",
      "e and seats] title : `tarzan' beautiful to look at , easy to\n",
      "e and seats] title : `tarzan' beautiful to look at , easy to\n",
      "s both visually and tellingly beautiful . alas , i have one \n",
      "lishing his title as the most beautiful ( and often talented\n",
      "the mystery . along the way a beautiful blonde ( gretchen mo\n",
      "wonderful as kala ( she has a beautiful singing voice , too \n",
      "wept away at the sight of the beautiful and popular sophomor\n",
      "hen we join that music to the beautiful scotch landscapes , \n",
      "tracted . first , there's the beautiful and imperious maxine\n",
      "ood that she's supposed to be beautiful , but underneath her\n",
      "cause it is a bond film , the beautiful women and nifty gadg\n",
      "cause it is a bond film , the beautiful women and nifty gadg\n",
      "ked . the film is filled with beautiful , subtle performance\n",
      "ked . the film is filled with beautiful , subtle performance\n",
      "f she loves her finace to the beautiful one of them hanging \n",
      "                      life is beautiful is a rare treat : a \n",
      "                      life is beautiful is a rare treat : a \n",
      "                      life is beautiful is a rare treat : a \n",
      "                      life is beautiful is a rare treat : a \n",
      "                      life is beautiful is a rare treat : a \n",
      " the first two hours are just beautiful sets and bad dialogu\n",
      " the first two hours are just beautiful sets and bad dialogu\n",
      " the first two hours are just beautiful sets and bad dialogu\n",
      "he presence of the obligatory beautiful girl . feldman write\n",
      "he presence of the obligatory beautiful girl . feldman write\n",
      " is suitably epic , with some beautiful tunes . coupled with\n",
      "ognizable musical score , the beautiful skyscrapers of new y\n",
      "ognizable musical score , the beautiful skyscrapers of new y\n",
      "ognizable musical score , the beautiful skyscrapers of new y\n",
      "hand turns out to belong to a beautiful , but mysterious wom\n",
      "aws , music of the heart is a beautiful film . that is not a\n",
      " must be to be so wealthy and beautiful , but to have no one\n",
      "ie is fun and romantic , with beautiful scenery and characte\n",
      "rpowering , but it gives us a beautiful window into the life\n",
      "ecret message recorded by the beautiful princess leia ( carr\n",
      "media empire , and raised two beautiful daughters , allison \n",
      "scarlett o'hara ( leigh ) , a beautiful southern belle with \n",
      "from his vacation to persuade beautiful thief nyah nordoff-h\n",
      "hrow in numerous shots of the beautiful irish scenery , and \n",
      "quite buy the fact that these beautiful , intelligent , sing\n",
      "estigious family and is quite beautiful . the marriage is on\n",
      "estigious family and is quite beautiful . the marriage is on\n",
      "k . the film is magnificently beautiful thanks primarily to \n",
      "pe . he is accompanied by his beautiful wife ilsa lund ( ber\n",
      "ut to its parent . absolutely beautiful stuff . the third se\n",
      "ut to its parent . absolutely beautiful stuff . the third se\n",
      " between seth and a human , a beautiful but sad heart surgeo\n",
      "bbing , drugs , sex , and the beautiful , beautiful music , \n",
      "bbing , drugs , sex , and the beautiful , beautiful music , \n",
      "into eight chapters parted by beautiful pictures made by dan\n",
      "in desperately in love with a beautiful woman ( roberts ) , \n",
      ". \" beauty and the beast \" 's beautiful belle , for instance\n",
      "ette includes an intro by the beautiful jane jensen and an i\n",
      "ette includes an intro by the beautiful jane jensen and an i\n",
      "an fiercely protective of his beautiful 20 year old sister ,\n",
      "an fiercely protective of his beautiful 20 year old sister ,\n",
      "rtship . secondly , buy her a beautiful ring that glitters a\n",
      " have more time to notice the beautiful art , vestments , an\n",
      " have more time to notice the beautiful art , vestments , an\n",
      " have more time to notice the beautiful art , vestments , an\n",
      "man side looking for the most beautiful one ) . the acting i\n",
      " when truman's world is still beautiful and perfect . when t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \"\"\"\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7683)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7460)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy (zmq/backend/cython/socket.c:2344)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:9621)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-239-131e4c4a9299>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"quit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"query> \"\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# use raw_input() in Python 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         )\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def raw(file):\n",
    "    contents = open(file).read()\n",
    "    contents = re.sub(r'<.*?>', ' ', contents)\n",
    "    contents = re.sub('\\s+', ' ', contents)\n",
    "    return contents\n",
    "\n",
    "def snippet(doc, term):\n",
    "    text = ' '*30 + raw(doc) + ' '*30\n",
    "    pos = text.index(term)\n",
    "    return text[pos-30:pos+30]\n",
    "\n",
    "print(\"Building Index...\")\n",
    "files = nltk.corpus.movie_reviews.abspaths()\n",
    "idx = nltk.Index((w, f) for f in files for w in raw(f).split())\n",
    "\n",
    "query = ''\n",
    "while query != \"quit\":\n",
    "    query = input(\"query> \")     # use raw_input() in Python 2\n",
    "    if query in idx:\n",
    "        for doc in idx[query]:\n",
    "            print(snippet(doc, query))\n",
    "    else:\n",
    "        print(\"Not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more subtle example of a space-time tradeoff involves replacing the tokens of a corpus with integer identifiers. We create a vocabulary for the corpus, a list in which each word is stored once, then invert this list so that we can look up any word to find its identifier. Each document is preprocessed, so that a list of words becomes a list of integers. Any language models can now work with integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Preprocess tagged corpus data, converting all words and tags to integers ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(tagged_corpus):\n",
    "    words = set()\n",
    "    tags = set()\n",
    "    for sent in tagged_corpus:\n",
    "        for word, tag in sent:\n",
    "            words.add(word)\n",
    "            tags.add(tag)\n",
    "    wm = dict((w, i) for (i, w) in enumerate(words))\n",
    "    tm = dict((t, i) for (i, t) in enumerate(tags))\n",
    "    return [[(wm[w], tm[t]) for (w, t) in sent] for sent in tagged_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example of a space-time tradeoff is maintaining a vocabulary list. If you need to process an input text to check that all words are in an existing vocabulary, the vocabulary should be stored as a set, not a list. The elements of a set are automatically indexed, so testing membership of a large set will be much faster than testing membership of the corresponding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> from timeit import Timer\n",
    ">>> vocab_size = 100000\n",
    ">>> setup_list = \"import random; vocab = range(%d)\" % vocab_size\n",
    ">>> setup_set = \"import random; vocab = set(range(%d))\" % vocab_size\n",
    ">>> statement = \"random.randint(0, %d) in vocab\" % (vocab_size * 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002703556965570897\n"
     ]
    }
   ],
   "source": [
    ">>> print(Timer(statement, setup_list).timeit(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0027781930402852595\n"
     ]
    }
   ],
   "source": [
    ">>> print(Timer(statement, setup_set).timeit(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic programming is a general technique for designing algorithms which is widely used in natural language processing. The term 'programming' is used in a different sense to what you might expect, to mean planning or scheduling. Dynamic programming is used when a problem contains overlapping sub-problems. Instead of computing solutions to these sub-problems repeatedly, we simply store them in a lookup table. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Four Ways to Compute Sanskrit Meter: (i) recursive; (ii) bottom-up dynamic programming; (iii) top-down dynamic programming; and (iv) built-in memoization.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def virahanka1(n):\n",
    "    if n == 0:\n",
    "        return [\"\"]\n",
    "    elif n == 1:\n",
    "        return [\"S\"]\n",
    "    else:\n",
    "        s = [\"S\" + prosody for prosody in virahanka1(n-1)]\n",
    "        l = [\"L\" + prosody for prosody in virahanka1(n-2)]\n",
    "        return s + l\n",
    "\n",
    "def virahanka2(n):\n",
    "    lookup = [[\"\"], [\"S\"]]\n",
    "    for i in range(n-1):\n",
    "        s = [\"S\" + prosody for prosody in lookup[i+1]]\n",
    "        l = [\"L\" + prosody for prosody in lookup[i]]\n",
    "        lookup.append(s + l)\n",
    "    return lookup[n]\n",
    "\n",
    "def virahanka3(n, lookup={0:[\"\"], 1:[\"S\"]}):\n",
    "    if n not in lookup:\n",
    "        s = [\"S\" + prosody for prosody in virahanka3(n-1)]\n",
    "        l = [\"L\" + prosody for prosody in virahanka3(n-2)]\n",
    "        lookup[n] = s + l\n",
    "    return lookup[n]\n",
    "\n",
    "from nltk import memoize\n",
    "@memoize\n",
    "def virahanka4(n):\n",
    "    if n == 0:\n",
    "        return [\"\"]\n",
    "    elif n == 1:\n",
    "        return [\"S\"]\n",
    "    else:\n",
    "        s = [\"S\" + prosody for prosody in virahanka4(n-1)]\n",
    "        l = [\"L\" + prosody for prosody in virahanka4(n-2)]\n",
    "        return s + l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SSSS', 'SSL', 'SLS', 'LSS', 'LL']"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> virahanka1(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SSSS', 'SSL', 'SLS', 'LSS', 'LL']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> virahanka2(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SSSS', 'SSL', 'SLS', 'LSS', 'LL']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> virahanka3(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SSSS', 'SSL', 'SLS', 'LSS', 'LL']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> virahanka4(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8   A Sample of Python Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has some libraries that are useful for visualizing language data. The Matplotlib package supports sophisticated plotting functions with a MATLAB-style interface, and is available from http://matplotlib.sourceforge.net/.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Frequency of Modals in Different Sections of the Brown Corpus***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import arange\n",
    "from matplotlib import pyplot\n",
    "\n",
    "colors = 'rgbcmyk' # red, green, blue, cyan, magenta, yellow, black\n",
    "\n",
    "def bar_chart(categories, words, counts):\n",
    "    \"Plot a bar chart showing counts for each word by category\"\n",
    "    ind = arange(len(words))\n",
    "    width = 1 / (len(categories) + 1)\n",
    "    bar_groups = []\n",
    "    for c in range(len(categories)):\n",
    "        bars = pyplot.bar(ind+c*width, counts[categories[c]], width,\n",
    "                         color=colors[c % len(colors)])\n",
    "        bar_groups.append(bars)\n",
    "    pyplot.xticks(ind+width, words)\n",
    "    pyplot.legend([b[0] for b in bar_groups], categories, loc='upper left')\n",
    "    pyplot.ylabel('Frequency')\n",
    "    pyplot.title('Frequency of Six Modal Verbs by Genre')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEICAYAAABF82P+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1129816d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    ">>> genres = ['news', 'religion', 'hobbies', 'government', 'adventure']\n",
    ">>> modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    ">>> cfdist = nltk.ConditionalFreqDist(\n",
    "...              (genre, word)\n",
    "...              for genre in genres\n",
    "...              for word in nltk.corpus.brown.words(categories=genre)\n",
    "...              if word in modals)\n",
    "...\n",
    ">>> counts = {}\n",
    ">>> for genre in genres:\n",
    "...     counts[genre] = [cfdist[genre][word] for word in modals]\n",
    ">>> bar_chart(genres, modals, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetworkX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NetworkX package is for defining and manipulating structures consisting of nodes and edges, known as graphs. It is available from https://networkx.lanl.gov/. NetworkX can be used in conjunction with Matplotlib to visualize networks, such as WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Using the NetworkX and Matplotlib Libraries***\n",
    "\n",
    "Visualization with NetworkX and Matplotlib: Part of the WordNet hypernym hierarchy is displayed, starting with dog.n.01 (the darkest node in the middle); node size is based on the number of children of the node, and color is based on the distance of the node from dog.n.01; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def traverse(graph, start, node):\n",
    "    graph.depth[node.name] = node.shortest_path_distance(start)\n",
    "    for child in node.hyponyms():\n",
    "        graph.add_edge(node.name, child.name)\n",
    "        traverse(graph, start, child)\n",
    "\n",
    "def hyponym_graph(start):\n",
    "    G = nx.Graph()\n",
    "    G.depth = {}\n",
    "    traverse(G, start, start)\n",
    "    return G\n",
    "\n",
    "def graph_draw(graph):\n",
    "    nx.draw_graphviz(graph,\n",
    "         node_size = [16 * graph.degree(n) for n in graph],\n",
    "         node_color = [graph.depth[n] for n in graph],\n",
    "         with_labels = False)\n",
    "    matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'networkx.drawing' has no attribute 'graphviz_layout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-261-df3988f7c424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dog.n.01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyponym_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgraph_draw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-260-1966172a641c>\u001b[0m in \u001b[0;36mgraph_draw\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     19\u001b[0m          \u001b[0mnode_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m          \u001b[0mnode_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m          with_labels = False)\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py\u001b[0m in \u001b[0;36mdraw_graphviz\u001b[0;34m(G, prog, **kwargs)\u001b[0m\n\u001b[1;32m    982\u001b[0m        \u001b[0mSee\u001b[0m \u001b[0mnetworkx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0mof\u001b[0m \u001b[0moptional\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     \"\"\"\n\u001b[0;32m--> 984\u001b[0;31m     \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraphviz_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m     \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'networkx.drawing' has no attribute 'graphviz_layout'"
     ]
    }
   ],
   "source": [
    ">>> dog = wn.synset('dog.n.01')\n",
    ">>> graph = hyponym_graph(dog)\n",
    ">>> graph_draw(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language analysis work often involves data tabulations, containing information about lexical items, or the participants in an empirical study, or the linguistic features extracted from a corpus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NumPy package provides substantial support for numerical processing in Python. NumPy has a multi-dimensional array object, which is easy to initialize and access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from numpy import array\n",
    ">>> cube = array([ [[0,0,0], [1,1,1], [2,2,2]],\n",
    "...                [[3,3,3], [4,4,4], [5,5,5]],\n",
    "...                [[6,6,6], [7,7,7], [8,8,8]] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> cube[1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 7, 8],\n",
       "       [6, 7, 8],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> cube[2].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 7, 7],\n",
       "       [8, 8, 8]])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> cube[2,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy includes linear algebra functions. Here we perform singular value decomposition on a matrix, an operation used in latent semantic analysis to help identify implicit concepts in a document collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.4472136  -0.89442719]\n",
      " [-0.89442719  0.4472136 ]]\n",
      "[ 6.32455532  3.16227766]\n",
      "[[-0.70710678  0.70710678]\n",
      " [-0.70710678 -0.70710678]]\n"
     ]
    }
   ],
   "source": [
    ">>> from numpy import linalg\n",
    ">>> a=array([[4,0], [3,-5]])\n",
    ">>> u,s,vt = linalg.svd(a)\n",
    ">>> print (u)\n",
    ">>> print (s)\n",
    ">>> print (vt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** NLTK's clustering package nltk.cluster makes extensive use of NumPy arrays, and includes support for k-means clustering, Gaussian EM clustering, group average agglomerative clustering, and dendrogram plots.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9   Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's assignment and parameter passing use object references; e.g. if a is a list and we assign b = a, then any operation on a will modify b, and vice versa.\n",
    "\n",
    "The ***is*** operation tests if two objects are identical internal objects, while ***==*** tests if two objects are equivalent. This distinction parallels the type-token distinction.\n",
    "\n",
    "Strings, lists and tuples are different kinds of sequence object, supporting common operations such as indexing, slicing, len(), sorted(), and membership testing using in.\n",
    "\n",
    "A declarative programming style usually produces more compact, readable code; manually-incremented loop variables are usually unnecessary; when a sequence must be enumerated, use  enumerate().\n",
    "\n",
    "Functions are an essential programming abstraction: key concepts to understand are parameter passing, variable scope, and docstrings.\n",
    "\n",
    "A function serves as a namespace: names defined inside a function are not visible outside that function, unless those names are declared to be global.\n",
    "\n",
    "Modules permit logically-related material to be localized in a file. A module serves as a namespace: names defined in a module — such as variables and functions — are not visible to other modules, unless those names are imported.\n",
    "\n",
    "Dynamic programming is an algorithm design technique used widely in NLP that stores the results of previous computations in order to avoid unnecessary recomputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
